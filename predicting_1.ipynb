{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0734e2c3",
   "metadata": {},
   "source": [
    "# IMMO-ELIZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16b32010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from category_encoders) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from category_encoders) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from category_encoders) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=1.6.0 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from category_encoders) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from category_encoders) (1.15.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from category_encoders) (0.14.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from scikit-learn>=1.6.0->category_encoders) (3.5.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: pgeocode in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pgeocode) (2.32.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pgeocode) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pgeocode) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pandas->pgeocode) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pandas->pgeocode) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pandas->pgeocode) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from requests->pgeocode) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from requests->pgeocode) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from requests->pgeocode) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from requests->pgeocode) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->pgeocode) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders\n",
    "!pip install pgeocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cce13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ridge_regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pgeocode\n",
    "import xgboost as xgb\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee1cef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/Kangaroo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fcdf431",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9da9469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                    0.0 %\n",
      "id                            0.0 %\n",
      "url                           0.0 %\n",
      "type                          0.0 %\n",
      "subtype                       0.0 %\n",
      "bedroomCount                 8.47 %\n",
      "bathroomCount               17.04 %\n",
      "province                      0.0 %\n",
      "locality                      0.0 %\n",
      "postCode                      0.0 %\n",
      "habitableSurface            15.66 %\n",
      "roomCount                   72.69 %\n",
      "monthlyCost                 100.0 %\n",
      "hasAttic                    84.43 %\n",
      "hasBasement                 63.52 %\n",
      "hasDressingRoom             96.73 %\n",
      "diningRoomSurface           91.41 %\n",
      "hasDiningRoom                82.4 %\n",
      "buildingCondition           27.84 %\n",
      "buildingConstructionYear     38.9 %\n",
      "facedeCount                 33.76 %\n",
      "floorCount                  53.28 %\n",
      "streetFacadeWidth            80.7 %\n",
      "hasLift                      76.3 %\n",
      "floodZoneType               44.67 %\n",
      "heatingType                 41.33 %\n",
      "hasHeatPump                  90.7 %\n",
      "hasPhotovoltaicPanels       89.99 %\n",
      "hasThermicPanels            96.13 %\n",
      "kitchenSurface              69.81 %\n",
      "kitchenType                 47.84 %\n",
      "landSurface                  50.8 %\n",
      "hasLivingRoom               46.65 %\n",
      "livingRoomSurface           63.98 %\n",
      "hasBalcony                  100.0 %\n",
      "hasGarden                   80.14 %\n",
      "gardenSurface               80.14 %\n",
      "gardenOrientation           93.03 %\n",
      "parkingCountIndoor          64.86 %\n",
      "parkingCountOutdoor          77.2 %\n",
      "hasAirConditioning           98.6 %\n",
      "hasArmoredDoor               95.4 %\n",
      "hasVisiophone                80.1 %\n",
      "hasOffice                   87.08 %\n",
      "toiletCount                 31.45 %\n",
      "hasSwimmingPool             97.74 %\n",
      "hasFireplace                96.21 %\n",
      "hasTerrace                  40.99 %\n",
      "terraceSurface              64.41 %\n",
      "terraceOrientation          85.99 %\n",
      "accessibleDisabledPeople    100.0 %\n",
      "epcScore                    18.64 %\n",
      "price                        4.97 %\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print((df.isna().mean() * 100).round(2).astype(str) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cca55c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 0\", \"url\"])\n",
    "\n",
    "df = df.drop(columns=['monthlyCost', 'hasBalcony', 'accessibleDisabledPeople', 'roomCount', 'diningRoomSurface', \n",
    "                      'streetFacadeWidth', 'gardenOrientation', 'kitchenSurface', 'floorCount', 'hasDiningRoom', \n",
    "                      'hasDressingRoom'])\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"id\"], keep=\"first\")\n",
    "\n",
    "binary_cols = [\n",
    "    'hasBasement', 'hasLift', 'hasHeatPump', 'hasPhotovoltaicPanels', \n",
    "    'hasAirConditioning', 'hasArmoredDoor', 'hasVisiophone', 'hasOffice', \n",
    "    'hasSwimmingPool', 'hasFireplace', 'parkingCountIndoor', 'parkingCountOutdoor',\n",
    "    'hasAttic'\n",
    "]\n",
    "\n",
    "for col in binary_cols:\n",
    "    df[col] = df[col].map({True: 1, False: 0, 'True': 1, 'False': 0}).fillna(0).astype(int)\n",
    "\n",
    "# Colonnes dépendantes d'autres colonnes\n",
    "df['hasLivingRoom'] = df['hasLivingRoom'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "df.loc[df['hasLivingRoom'].isna(), 'hasLivingRoom'] = df['livingRoomSurface'].notnull().astype(int)\n",
    "\n",
    "df['hasGarden'] = df['hasGarden'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "df.loc[df['hasGarden'].isna(), 'hasGarden'] = df['gardenSurface'].notnull().astype(int)\n",
    "\n",
    "df['hasTerrace'] = df['hasTerrace'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "df.loc[df['hasTerrace'].isna(), 'hasTerrace'] = df['terraceSurface'].notnull().astype(int)\n",
    "\n",
    "df['hasGarden'] = df['hasGarden'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "\n",
    "# When hasLivingRoom = 0 ; livingRoomSurface = 0\n",
    "df.loc[df['hasLivingRoom'] == 0, 'livingRoomSurface'] = 0\n",
    "\n",
    "# When hasGarden = 0 ; gardenSurface = 0\n",
    "df.loc[df['hasGarden'] == 0, 'gardenSurface'] = 0\n",
    "\n",
    "# When hasTerrace = 0 ; terraceSurface = 0 and terraceOrientation = 0\n",
    "df.loc[df['hasTerrace'] == 0, 'terraceSurface'] = 0\n",
    "df.loc[df['hasTerrace'] == 0, 'terraceOrientation'] = 0\n",
    "\n",
    "#drop number of facade bigger than 4 and transform \"facedeCount\" into \"facadeCount\"\n",
    "df['facadeCount'] = df['facedeCount']\n",
    "df = df.drop(columns='facedeCount')\n",
    "df['facadeCount'] = df['facadeCount'].fillna(2)\n",
    "df = df[df['facadeCount'] <= 4]\n",
    "\n",
    "# drop lines without price\n",
    "df = df.dropna(subset=\"price\")\n",
    "\n",
    "# bedroomCount : lets assume that they have at least one so fill nan by 1\n",
    "df['bedroomCount'] = df['bedroomCount'].fillna(1).astype(float)\n",
    "\n",
    "# bathroomCount same as bedrooms\n",
    "df['bathroomCount'] = df['bathroomCount'].fillna(1).astype(float)\n",
    "\n",
    "# toiletCount same as bedrooms\n",
    "df['toiletCount'] = df['toiletCount'].fillna(1).astype(float)\n",
    "\n",
    "# habitableSurface : replace by median \n",
    "df['habitableSurface'] = df['habitableSurface'].fillna(df['habitableSurface'].median())\n",
    "\n",
    "# buildingCondition : replace by 'NOT_MENTIONED\n",
    "df['buildingCondition'] = df['buildingCondition'].fillna('NOT_MENTIONED')\n",
    "\n",
    "# buildingConstructionYear\n",
    "df['buildingConstructionYear'] = df['buildingConstructionYear'].fillna(df['buildingConstructionYear'].median()).astype(int)\n",
    "\n",
    "\n",
    "# floodZoneType lts assume that missing values are NON_FLOOD_ZONE\n",
    "df['floodZoneType'] = df['floodZoneType'].fillna('NON_FLOOD_ZONE')\n",
    "\n",
    "# heatingType\n",
    "df['heatingType'] = df['heatingType'].fillna(df['heatingType'].mode()[0])\n",
    "\n",
    "# hasThermicPanels lets assume that if its not precised, there are not\n",
    "df['hasThermicPanels'] = df['hasThermicPanels'].fillna(0).astype(float)\n",
    "\n",
    "# kitchenType\n",
    "df['kitchenType'] = df['kitchenType'].fillna(df['kitchenType'].mode()[0])\n",
    "\n",
    "# landSurface\n",
    "df['landSurface'] = df['landSurface'].fillna(df['landSurface'].median())\n",
    "\n",
    "# livingRoomSurface\n",
    "df['livingRoomSurface'] = df['livingRoomSurface'].fillna(df['livingRoomSurface'].median())\n",
    "\n",
    "# terraceSurface\n",
    "median_terrace = df.loc[(df['hasTerrace'] == 1) & (df['terraceSurface'].notnull()), 'terraceSurface'].median()\n",
    "df.loc[(df['hasTerrace'] == 1) & (df['terraceSurface'].isna()), 'terraceSurface'] = median_terrace\n",
    "df.loc[(df['hasTerrace'] != 1) & (df['terraceSurface'].isna()), 'terraceSurface'] = 0\n",
    "\n",
    "# terraceOrientation\n",
    "mode_terrace = df.loc[(df['hasTerrace'] == 1), 'terraceOrientation'].mode()[0]\n",
    "df.loc[(df['hasTerrace'] == 1) & (df['terraceOrientation'].isna()), 'terraceOrientation'] = mode_terrace\n",
    "df.loc[(df['hasTerrace'] != 1) & (df['terraceOrientation'].isna()), 'terraceOrientation'] = 'NO_TERRACE'\n",
    "\n",
    "# epcScore\n",
    "epc_order = ['A++', 'A+', 'A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "df = df[df['epcScore'].isin(epc_order)]\n",
    "df['epcScore'] = df['epcScore'].fillna(df['epcScore'].mode()[0])\n",
    "\n",
    "def transform_data_types(df, col_types):\n",
    "    for col, dtype in col_types.items():\n",
    "        df[col] = df[col].astype(dtype)\n",
    "    return df\n",
    "\n",
    "col_types = {'id': 'int', 'type': 'str', 'subtype': 'str', 'bedroomCount': 'int', 'bathroomCount': 'int',\n",
    "             'province': 'str', 'locality': 'str', 'postCode': 'int', 'habitableSurface': 'float', \n",
    "             'hasBasement': 'int', 'buildingCondition': 'str',\n",
    "             'buildingConstructionYear': 'int', 'hasLift': 'int', 'floodZoneType': 'str',\n",
    "             'heatingType': 'str', 'hasHeatPump': 'int', 'hasPhotovoltaicPanels': 'int', 'hasThermicPanels': 'int',\n",
    "             'kitchenType': 'str', 'landSurface': 'float', 'hasLivingRoom': 'int', 'livingRoomSurface': 'float',\n",
    "             'hasGarden': 'int', 'gardenSurface': 'float', 'parkingCountIndoor': 'int', 'parkingCountOutdoor': 'int',\n",
    "             'hasAirConditioning': 'int', 'hasArmoredDoor': 'int', 'hasVisiophone': 'int', 'hasOffice': 'int', \n",
    "             'toiletCount': 'int', 'hasSwimmingPool': 'int', 'hasFireplace': 'int', 'hasTerrace': 'int', 'terraceSurface': 'float',\n",
    "             'terraceOrientation': 'str', 'epcScore': 'str', 'price': 'float', 'facadeCount': 'int'}\n",
    "\n",
    "df = transform_data_types(df, col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74a67b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'type', 'subtype', 'bedroomCount', 'bathroomCount', 'province',\n",
       "       'locality', 'postCode', 'habitableSurface', 'hasAttic', 'hasBasement',\n",
       "       'buildingCondition', 'buildingConstructionYear', 'hasLift',\n",
       "       'floodZoneType', 'heatingType', 'hasHeatPump', 'hasPhotovoltaicPanels',\n",
       "       'hasThermicPanels', 'kitchenType', 'landSurface', 'hasLivingRoom',\n",
       "       'livingRoomSurface', 'hasGarden', 'gardenSurface', 'parkingCountIndoor',\n",
       "       'parkingCountOutdoor', 'hasAirConditioning', 'hasArmoredDoor',\n",
       "       'hasVisiophone', 'hasOffice', 'toiletCount', 'hasSwimmingPool',\n",
       "       'hasFireplace', 'hasTerrace', 'terraceSurface', 'terraceOrientation',\n",
       "       'epcScore', 'price', 'facadeCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "762a7e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of nan values : \n",
      "id                          0.0 %\n",
      "type                        0.0 %\n",
      "subtype                     0.0 %\n",
      "bedroomCount                0.0 %\n",
      "bathroomCount               0.0 %\n",
      "province                    0.0 %\n",
      "locality                    0.0 %\n",
      "postCode                    0.0 %\n",
      "habitableSurface            0.0 %\n",
      "hasAttic                    0.0 %\n",
      "hasBasement                 0.0 %\n",
      "buildingCondition           0.0 %\n",
      "buildingConstructionYear    0.0 %\n",
      "hasLift                     0.0 %\n",
      "floodZoneType               0.0 %\n",
      "heatingType                 0.0 %\n",
      "hasHeatPump                 0.0 %\n",
      "hasPhotovoltaicPanels       0.0 %\n",
      "hasThermicPanels            0.0 %\n",
      "kitchenType                 0.0 %\n",
      "landSurface                 0.0 %\n",
      "hasLivingRoom               0.0 %\n",
      "livingRoomSurface           0.0 %\n",
      "hasGarden                   0.0 %\n",
      "gardenSurface               0.0 %\n",
      "parkingCountIndoor          0.0 %\n",
      "parkingCountOutdoor         0.0 %\n",
      "hasAirConditioning          0.0 %\n",
      "hasArmoredDoor              0.0 %\n",
      "hasVisiophone               0.0 %\n",
      "hasOffice                   0.0 %\n",
      "toiletCount                 0.0 %\n",
      "hasSwimmingPool             0.0 %\n",
      "hasFireplace                0.0 %\n",
      "hasTerrace                  0.0 %\n",
      "terraceSurface              0.0 %\n",
      "terraceOrientation          0.0 %\n",
      "epcScore                    0.0 %\n",
      "price                       0.0 %\n",
      "facadeCount                 0.0 %\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of nan values : \")\n",
    "print((df.isna().mean() * 100).round(2).astype(str) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87beb86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                            int64\n",
      "type                         object\n",
      "subtype                      object\n",
      "bedroomCount                  int64\n",
      "bathroomCount                 int64\n",
      "province                     object\n",
      "locality                     object\n",
      "postCode                      int64\n",
      "habitableSurface            float64\n",
      "hasAttic                      int64\n",
      "hasBasement                   int64\n",
      "buildingCondition            object\n",
      "buildingConstructionYear      int64\n",
      "hasLift                       int64\n",
      "floodZoneType                object\n",
      "heatingType                  object\n",
      "hasHeatPump                   int64\n",
      "hasPhotovoltaicPanels         int64\n",
      "hasThermicPanels              int64\n",
      "kitchenType                  object\n",
      "landSurface                 float64\n",
      "hasLivingRoom                 int64\n",
      "livingRoomSurface           float64\n",
      "hasGarden                     int64\n",
      "gardenSurface               float64\n",
      "parkingCountIndoor            int64\n",
      "parkingCountOutdoor           int64\n",
      "hasAirConditioning            int64\n",
      "hasArmoredDoor                int64\n",
      "hasVisiophone                 int64\n",
      "hasOffice                     int64\n",
      "toiletCount                   int64\n",
      "hasSwimmingPool               int64\n",
      "hasFireplace                  int64\n",
      "hasTerrace                    int64\n",
      "terraceSurface              float64\n",
      "terraceOrientation           object\n",
      "epcScore                     object\n",
      "price                       float64\n",
      "facadeCount                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07abb479",
   "metadata": {},
   "source": [
    "## Keep only houses between 100.000 and 1.000.000€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1af4909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59267, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df[(df['price']<1000000) & (df['price']>100000)]\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54b8f1",
   "metadata": {},
   "source": [
    "## Handle categrical data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d50b73",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['province'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m df_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misHouse\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (df_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHOUSE\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# subtype -> in pipeline\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# province ? drop or dummies ?\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df_clean \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df_clean, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprovince\u001b[39m\u001b[38;5;124m'\u001b[39m], prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprovince\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# locality ? drop because zipcode\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# building condition \u001b[39;00m\n\u001b[1;32m     11\u001b[0m condition_rating \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto restore\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto renovate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas new\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     18\u001b[0m }\n",
      "File \u001b[0;32m/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/pandas/core/reshape/encoding.py:169\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m data[columns]\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_len\u001b[39m(item, name: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['province'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Type into isHouse -> if false : Apartment\n",
    "df_clean['isHouse'] = (df_clean['type'] == 'HOUSE').astype(bool)\n",
    "\n",
    "# subtype -> in pipeline\n",
    "\n",
    "# province ? drop or dummies ?\n",
    "df_clean = pd.get_dummies(df_clean, columns=['province'], prefix='province')\n",
    "# locality ? drop because zipcode\n",
    "\n",
    "# building condition \n",
    "condition_rating = {\n",
    "    'to restore': 0,\n",
    "    'to renovate': 1,\n",
    "    'to be done up': 2,\n",
    "    'good': 3,\n",
    "    'just renovated': 4,\n",
    "    'as new': 5\n",
    "}\n",
    "df_clean['buildingCondition'] = (df_clean['buildingCondition'].astype(str).str.strip().str.lower()\n",
    "                                    .map(condition_rating).fillna(-1).astype(int))\n",
    "\n",
    "\n",
    "# heatingType\n",
    "df_clean = pd.get_dummies(df_clean, columns=['heatingType'], prefix='heating')\n",
    "\n",
    "# kitchenType\n",
    "df_clean['kitchenScore'] = df_clean['kitchenType'].map({\n",
    "    'Not equipped': 0,\n",
    "    'Semi equipped': 1,\n",
    "    'Installed': 2,\n",
    "    'Hyper equipped': 3,\n",
    "    'USA semi equipped': 1,\n",
    "    'USA hyper equipped': 3\n",
    "})\n",
    "\n",
    "# epcScore\n",
    "epc_score_rating = {\n",
    "    'A++': 10,\n",
    "    'A+': 9,\n",
    "    'A': 8,\n",
    "    'B': 7,\n",
    "    'C': 6,\n",
    "    'D': 5,\n",
    "    'E': 4,\n",
    "    'F': 3,\n",
    "    'G': 2,\n",
    "    'G_F': 1\n",
    "}\n",
    "df_clean['epcScore'] = (\n",
    "    df_clean['epcScore']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.upper()\n",
    "    .map(epc_score_rating)\n",
    ")\n",
    "\n",
    "df_clean = df_clean.drop(columns=['type', 'heatingType', 'terraceOrientation', 'province'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9ce23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epcToNumeric(row):\n",
    "    region = row['region']\n",
    "    epc_score = row['epcScore']\n",
    "    \n",
    "    epc_mapping = {\n",
    "        'Flanders': {\n",
    "            'A++': 0,\n",
    "            'A+': 0,\n",
    "            'A': 100,\n",
    "            'B': 200,\n",
    "            'C': 300,\n",
    "            'D': 400,\n",
    "            'E': 500,\n",
    "            'F': 600,\n",
    "            'G': 700\n",
    "        },\n",
    "        'Wallonia': {\n",
    "            'A++': 0,\n",
    "            'A+': 50,\n",
    "            'A': 90,\n",
    "            'B': 170,\n",
    "            'C': 250,\n",
    "            'D': 330,\n",
    "            'E': 420,\n",
    "            'F': 510,\n",
    "            'G': 600\n",
    "        },\n",
    "        'Bruxelles': {\n",
    "            'A++': 0,\n",
    "            'A+': 0,\n",
    "            'A': 45,\n",
    "            'B': 95,\n",
    "            'C': 145,\n",
    "            'D': 210,\n",
    "            'E': 275,\n",
    "            'F': 345,\n",
    "            'G': 450\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return epc_mapping.get(region, {}).get(epc_score, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0065aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricePerM2(df):\n",
    "    df['pricePerM2'] = df['price']/df['habitableSurface']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0868822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoordinates(df):\n",
    "    nomi = pgeocode.Nominatim('be')\n",
    "    \n",
    "    unique_postcodes = df[\"postCode\"].astype(str).unique()\n",
    "\n",
    "    geo_df = nomi.query_postal_code(list(unique_postcodes))\n",
    "\n",
    "    geo_df = geo_df[['postal_code', 'latitude', 'longitude']]\n",
    "    geo_df = geo_df.rename(columns={'postal_code': 'postCode'})\n",
    "\n",
    "    df['postCode'] = df['postCode'].astype(str)\n",
    "    geo_df['postCode'] = geo_df['postCode'].astype(str)\n",
    "\n",
    "    df = df.merge(geo_df, on='postCode', how='left')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a cleaning function :\n",
    "\n",
    "def transform_data_types(df, col_types):\n",
    "        for col, dtype in col_types.items():\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        return df\n",
    "\n",
    "def cleaning(df):\n",
    "    df = df.drop(columns=[\"Unnamed: 0\", \"url\"])\n",
    "\n",
    "    df = df.drop(columns=['monthlyCost', 'hasBalcony', 'accessibleDisabledPeople', 'roomCount', 'diningRoomSurface', \n",
    "                          'streetFacadeWidth', 'gardenOrientation', 'kitchenSurface', 'floorCount', 'hasDiningRoom', \n",
    "                          'hasDressingRoom'])\n",
    "    \n",
    "    \n",
    "    binary_cols = [\n",
    "        'hasBasement', 'hasLift', 'hasHeatPump', 'hasPhotovoltaicPanels', \n",
    "        'hasAirConditioning', 'hasArmoredDoor', 'hasVisiophone', 'hasOffice', \n",
    "        'hasSwimmingPool', 'hasFireplace', 'parkingCountIndoor', 'parkingCountOutdoor',\n",
    "        'hasAttic'\n",
    "    ]\n",
    "    \n",
    "    for col in binary_cols:\n",
    "        df[col] = df[col].map({True: 1, False: 0, 'True': 1, 'False': 0}).fillna(0).astype(int)\n",
    "    \n",
    "    # Colonnes dépendantes d'autres colonnes\n",
    "    df['hasLivingRoom'] = df['hasLivingRoom'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "    df.loc[df['hasLivingRoom'].isna(), 'hasLivingRoom'] = df['livingRoomSurface'].notnull().astype(int)\n",
    "    \n",
    "    df['hasGarden'] = df['hasGarden'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "    df.loc[df['hasGarden'].isna(), 'hasGarden'] = df['gardenSurface'].notnull().astype(int)\n",
    "    \n",
    "    df['hasTerrace'] = df['hasTerrace'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "    df.loc[df['hasTerrace'].isna(), 'hasTerrace'] = df['terraceSurface'].notnull().astype(int)\n",
    "    \n",
    "    # When hasLivingRoom = 0 ; livingRoomSurface = 0\n",
    "    df.loc[df['hasLivingRoom'] == 0, 'livingRoomSurface'] = 0\n",
    "    \n",
    "    # When hasGarden = 0 ; gardenSurface = 0\n",
    "    df.loc[df['hasGarden'] == 0, 'gardenSurface'] = 0\n",
    "    \n",
    "    # When hasTerrace = 0 ; terraceSurface = 0 and terraceOrientation = 0\n",
    "    df.loc[df['hasTerrace'] == 0, 'terraceSurface'] = 0\n",
    "    df.loc[df['hasTerrace'] == 0, 'terraceOrientation'] = 0\n",
    "    \n",
    "    #drop number of facade bigger than 4 and transform \"facedeCount\" into \"facadeCount\"\n",
    "    df['facadeCount'] = df['facedeCount']\n",
    "    df = df.drop(columns='facedeCount')\n",
    "    df['facadeCount'] = df['facadeCount'].fillna(2)\n",
    "    '''df = df[df['facadeCount'] <= 4]'''\n",
    "    \n",
    "    # bedroomCount : lets assume that they have at least one so fill nan by 1\n",
    "    df['bedroomCount'] = df['bedroomCount'].fillna(1).astype(float)\n",
    "    \n",
    "    # bathroomCount same as bedrooms\n",
    "    df['bathroomCount'] = df['bathroomCount'].fillna(1).astype(float)\n",
    "    \n",
    "    # toiletCount same as bedrooms\n",
    "    df['toiletCount'] = df['toiletCount'].fillna(1).astype(float)\n",
    "    \n",
    "    # habitableSurface : replace by median \n",
    "    #df['habitableSurface'] = df['habitableSurface'].fillna(df['habitableSurface'].median())\n",
    "    mediane_by_subtype = df.groupby('subtype')['habitableSurface'].median()\n",
    "    df['habitableSurface'] = df.apply(\n",
    "        lambda row: mediane_by_subtype[row['subtype']] if pd.isna(row['habitableSurface']) else row['habitableSurface'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # buildingCondition : replace by 'NOT_MENTIONED\n",
    "    df['buildingCondition'] = df['buildingCondition'].fillna('NOT_MENTIONED')\n",
    "    \n",
    "    # buildingConstructionYear\n",
    "    df['buildingConstructionYear'] = df['buildingConstructionYear'].fillna(df['buildingConstructionYear'].median()).astype(int)\n",
    "    \n",
    "    \n",
    "    # floodZoneType lts assume that missing values are NON_FLOOD_ZONE\n",
    "    df['floodZoneType'] = df['floodZoneType'].fillna('NON_FLOOD_ZONE')\n",
    "    \n",
    "    # heatingType\n",
    "    df['heatingType'] = df['heatingType'].fillna(df['heatingType'].mode()[0])\n",
    "    \n",
    "    # hasThermicPanels lets assume that if its not precised, there are not\n",
    "    df['hasThermicPanels'] = df['hasThermicPanels'].fillna(0).astype(float)\n",
    "    \n",
    "    # kitchenType\n",
    "    df['kitchenType'] = df['kitchenType'].fillna(df['kitchenType'].mode()[0])\n",
    "    \n",
    "    # landSurface\n",
    "    df['landSurface'] = df['landSurface'].fillna(df['landSurface'].median())\n",
    "    \n",
    "    # livingRoomSurface\n",
    "    df['livingRoomSurface'] = df['livingRoomSurface'].fillna(df['livingRoomSurface'].median())\n",
    "    \n",
    "    # terraceSurface\n",
    "    median_terrace = df.loc[(df['hasTerrace'] == 1) & (df['terraceSurface'].notnull()), 'terraceSurface'].median()\n",
    "    df.loc[(df['hasTerrace'] == 1) & (df['terraceSurface'].isna()), 'terraceSurface'] = median_terrace\n",
    "    df.loc[(df['hasTerrace'] != 1) & (df['terraceSurface'].isna()), 'terraceSurface'] = 0\n",
    "    \n",
    "    # terraceOrientation\n",
    "    mode_terrace = df.loc[(df['hasTerrace'] == 1), 'terraceOrientation'].mode()[0]\n",
    "    df.loc[(df['hasTerrace'] == 1) & (df['terraceOrientation'].isna()), 'terraceOrientation'] = mode_terrace\n",
    "    df.loc[(df['hasTerrace'] != 1) & (df['terraceOrientation'].isna()), 'terraceOrientation'] = 'NO_TERRACE'\n",
    "\n",
    "    \n",
    "    col_types = {'id': 'int', 'type': 'str', 'subtype': 'str', 'bedroomCount': 'int', 'bathroomCount': 'int',\n",
    "                 'province': 'str', 'locality': 'str', 'postCode': 'int', 'habitableSurface': 'float', \n",
    "                 'hasBasement': 'int', 'buildingCondition': 'str',\n",
    "                 'buildingConstructionYear': 'int', 'hasLift': 'int', 'floodZoneType': 'str',\n",
    "                 'heatingType': 'str', 'hasHeatPump': 'int', 'hasPhotovoltaicPanels': 'int', 'hasThermicPanels': 'int',\n",
    "                 'kitchenType': 'str', 'landSurface': 'float', 'hasLivingRoom': 'int', 'livingRoomSurface': 'float',\n",
    "                 'hasGarden': 'int', 'gardenSurface': 'float', 'parkingCountIndoor': 'int', 'parkingCountOutdoor': 'int',\n",
    "                 'hasAirConditioning': 'int', 'hasArmoredDoor': 'int', 'hasVisiophone': 'int', 'hasOffice': 'int', \n",
    "                 'toiletCount': 'int', 'hasSwimmingPool': 'int', 'hasFireplace': 'int', 'hasTerrace': 'int', 'terraceSurface': 'float',\n",
    "                 'terraceOrientation': 'str', 'epcScore': 'str', 'facadeCount': 'int'}\n",
    "    \n",
    "    df = transform_data_types(df, col_types)\n",
    "###\n",
    "###\n",
    "###\n",
    "    # Type into isHouse -> if false : Apartment\n",
    "    df['isHouse'] = (df['type'] == 'HOUSE').astype(int)\n",
    "\n",
    "    # subtype -> in pipeline\n",
    "\n",
    "    # province ? drop or dummies ?\n",
    "    df = pd.get_dummies(df, columns=['province'], prefix='province', dtype=int)\n",
    "    \n",
    "    # locality ? drop because zipcode\n",
    "\n",
    "    # building condition \n",
    "    condition_rating = {\n",
    "        'to restore': 0,\n",
    "        'to renovate': 1,\n",
    "        'to be done up': 2,\n",
    "        'good': 3,\n",
    "        'just renovated': 4,\n",
    "        'as new': 5\n",
    "    }\n",
    "    df['buildingCondition'] = (df['buildingCondition'].astype(str).str.strip().str.lower()\n",
    "                                    .map(condition_rating).fillna(-1).astype(int))\n",
    "\n",
    "    # floodzone type \n",
    "    df['floodZoneType'] = (df['floodZoneType'] != 'NON_FLOOD_ZONE').astype(int)\n",
    "    \n",
    "    # heatingType\n",
    "    df = pd.get_dummies(df, columns=['heatingType'], prefix='heating', dtype=int)\n",
    "    \n",
    "    # kitchenType\n",
    "    df = pd.get_dummies(df, columns=['kitchenType'], prefix='kitchen', dtype=int)\n",
    "\n",
    "    # add region information\n",
    "    def get_region(zip_code):\n",
    "        if 1000 <= zip_code <= 1299:\n",
    "            return \"Bruxelles\"\n",
    "        elif 1300 <= zip_code <= 1499 or 4000 <= zip_code <= 7999:\n",
    "            return \"Wallonia\"\n",
    "        else:\n",
    "            return \"Flanders\"\n",
    "    \n",
    "    df['region'] = df['postCode'].apply(get_region)\n",
    "\n",
    "    # epcScore\n",
    "    df['epcScore'] = df.apply(epcToNumeric, axis=1)\n",
    "\n",
    "    df = pricePerM2(df)\n",
    "    df = getCoordinates(df)\n",
    "    \n",
    "    df = df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "    df = df.drop(columns=['type', 'locality', 'region'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81886666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdePriceM2ProvinceKNN(df):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    coords_scaled = scaler.fit_transform(df[['latitude', 'longitude']])\n",
    "\n",
    "    k = 20 \n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    knn.fit(coords_scaled)\n",
    "    distances, indices = knn.kneighbors(coords_scaled)\n",
    "\n",
    "    kde_scores = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        neighbor_idxs = indices[i]\n",
    "        neighbor_prices = df['pricePerM2'].iloc[neighbor_idxs].dropna()\n",
    "\n",
    "        if len(neighbor_prices) < 2:\n",
    "            kde_scores.append(np.nan)\n",
    "        else:\n",
    "            kde = gaussian_kde(neighbor_prices)\n",
    "            density = kde(df['pricePerM2'].iloc[i])\n",
    "            kde_scores.append(density[0])\n",
    "\n",
    "    df['kde_price_per_m2_knn'] = kde_scores\n",
    "\n",
    "    df = df.drop(columns=['pricePerM2', 'latitude', 'longitude'])\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168c0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/Kangaroo.csv\")\n",
    "df = df.drop_duplicates(subset=[\"id\"], keep=\"first\")\n",
    "df = df[(df['price']<2000000) & (df['price']>100000)]\n",
    "\n",
    "# drop lines without price\n",
    "df = df.dropna(subset=\"price\")\n",
    "# epcScore\n",
    "epc_order = ['A++', 'A+', 'A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "df = df[df['epcScore'].isin(epc_order)]\n",
    "df['epcScore'] = df['epcScore'].fillna(df['epcScore'].mode()[0])\n",
    "\n",
    "transform_data_types(df, {'price':float})\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = cleaning(df_train)\n",
    "df_test = cleaning(df_test)\n",
    "\n",
    "df_train = kdePriceM2ProvinceKNN(df_train)\n",
    "df_test = kdePriceM2ProvinceKNN(df_test)\n",
    "\n",
    "X_train = df_train.drop(columns=['price'])\n",
    "y_train = df_train['price']\n",
    "X_test = df_test.drop(columns=['price'])\n",
    "y_test = df_test['price']\n",
    "\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcac69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression : MAE = 125018.7514, MSE = 37858284419.1513, accuracy = 65.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+14, tolerance: 4.017e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso : MAE = 125018.6187, MSE = 37858279429.0502, accuracy = 65.0325\n",
      "DecisionTree : MAE = 99555.3496, MSE = 29712602325.9207, accuracy = 74.8266\n",
      "RandomForest : MAE = 72203.4755, MSE = 14797549633.3701, accuracy = 81.4964\n",
      "ElasticNet : MAE = 124787.2085, MSE = 40304657653.1282, accuracy = 65.5949\n",
      "XGBoost : MAE = 63450.9390, MSE = 11229556288.8620, accuracy = 83.4498\n"
     ]
    }
   ],
   "source": [
    "# select multiple models\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Lasso': linear_model.Lasso(alpha=0.1),\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=0),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=2000, random_state=42, learning_rate=0.1),\n",
    "    'SVR': SVR(kernel='rbf', C=1.0, epsilon=0.2),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42),\n",
    "    'LightGBM': lgb.LGBMRegressor(random_state=42),\n",
    "    'CatBoost': CatBoostRegressor(random_state=42, silent=True),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'MLP': MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_mae = float('inf')\n",
    "best_model_name = ''\n",
    "best_pipeline = Pipeline([])\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('encoder', ce.TargetEncoder(cols=['subtype', 'terraceOrientation'])),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train.drop(columns='id'), y_train)\n",
    "\n",
    "    preds = pipeline.predict(X_test.drop(columns='id'))\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "\n",
    "    errors = abs(preds - y_test)\n",
    "    mape = 100 * (errors / y_test)\n",
    "    # Calculate and display accuracy\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    print(f\"{name} : MAE = {mae:.4f}, MSE = {mse:.4f}, accuracy = {accuracy:.4f}\")\n",
    "\n",
    "    results[name] = mae\n",
    "\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_mse = mse\n",
    "        best_accuracy = accuracy\n",
    "        best_model_name = name\n",
    "        best_pipeline = pipeline\n",
    "        best_model = model\n",
    "\n",
    "print(\"Models results :\")\n",
    "for model_name, mae in results.items():\n",
    "    print(f\"{model_name} : MAE = {mae:.4f}ler\")\n",
    "\n",
    "print(f\"\\n -> Best Model : {best_model_name} with MAE = {best_mae:.4f} and MSE = {best_mse:.4f}; accuracy = {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cb16f3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:                                                       Feature  Importance\n",
      "4                                            habitableSurface    0.660922\n",
      "68                                       kde_price_per_m2_knn    0.247751\n",
      "3                                                    postCode    0.227995\n",
      "13                                                landSurface    0.063087\n",
      "30                                                   epcScore    0.054287\n",
      "2                                               bathroomCount    0.041386\n",
      "0                                                     subtype    0.023197\n",
      "1                                                bedroomCount    0.022862\n",
      "43                                     province_West Flanders    0.017198\n",
      "8                                    buildingConstructionYear    0.010532\n",
      "9                                                     hasLift    0.007459\n",
      "24                                                toiletCount    0.007191\n",
      "32                                                    isHouse    0.006427\n",
      "37                                           province_Hainaut    0.005973\n",
      "60                                     kitchen_HYPER_EQUIPPED    0.003776\n",
      "34                                          province_Brussels    0.003106\n",
      "15                                          livingRoomSurface    0.003070\n",
      "31                                                facadeCount    0.001952\n",
      "25                                            hasSwimmingPool    0.001923\n",
      "42                                   province_Walloon Brabant    0.001899\n",
      "22                                              hasVisiophone    0.001677\n",
      "28                                             terraceSurface    0.001517\n",
      "39                                             province_Liège    0.001270\n",
      "63                                      kitchen_SEMI_EQUIPPED    0.001089\n",
      "26                                               hasFireplace    0.001051\n",
      "14                                              hasLivingRoom    0.001014\n",
      "17                                              gardenSurface    0.000999\n",
      "21                                             hasArmoredDoor    0.000942\n",
      "29                                         terraceOrientation    0.000883\n",
      "7                                           buildingCondition    0.000763\n",
      "5                                                    hasAttic    0.000648\n",
      "61                                          kitchen_INSTALLED    0.000627\n",
      "23                                                  hasOffice    0.000619\n",
      "10                                                hasHeatPump    0.000598\n",
      "62                                      kitchen_NOT_INSTALLED    0.000486\n",
      "6                                                 hasBasement    0.000485\n",
      "36                                   province_Flemish Brabant    0.000460\n",
      "41                                             province_Namur    0.000384\n",
      "33                                           province_Antwerp    0.000343\n",
      "64                                 kitchen_USA_HYPER_EQUIPPED    0.000262\n",
      "16                                                  hasGarden    0.000248\n",
      "11                                      hasPhotovoltaicPanels    0.000186\n",
      "55                                            heating_FUELOIL    0.000172\n",
      "12                                           hasThermicPanels    0.000169\n",
      "40                                        province_Luxembourg    0.000156\n",
      "46                                   floodZone_NON_FLOOD_ZONE    0.000074\n",
      "54                                           heating_ELECTRIC    0.000070\n",
      "18                                         parkingCountIndoor    0.000050\n",
      "65                                      kitchen_USA_INSTALLED    0.000045\n",
      "53                                             heating_CARBON    0.000037\n",
      "57                                             heating_PELLET    0.000036\n",
      "67                                    kitchen_USA_UNINSTALLED    0.000027\n",
      "20                                         hasAirConditioning    0.000025\n",
      "59                                               heating_WOOD    0.000019\n",
      "27                                                 hasTerrace    0.000009\n",
      "56                                                heating_GAS    0.000003\n",
      "58                                              heating_SOLAR    0.000000\n",
      "66                                  kitchen_USA_SEMI_EQUIPPED    0.000000\n",
      "49          floodZone_POSSIBLE_N_CIRCUMSCRIBED_WATERSIDE_ZONE    0.000000\n",
      "52  floodZone_RECOGNIZED_N_CIRCUMSCRIBED_WATERSIDE_FLOOD_ZONE    0.000000\n",
      "45                     floodZone_CIRCUMSCRIBED_WATERSIDE_ZONE    0.000000\n",
      "44                         floodZone_CIRCUMSCRIBED_FLOOD_ZONE    0.000000\n",
      "35                                     province_East Flanders    0.000000\n",
      "47                              floodZone_POSSIBLE_FLOOD_ZONE   -0.000003\n",
      "48              floodZone_POSSIBLE_N_CIRCUMSCRIBED_FLOOD_ZONE   -0.000015\n",
      "51            floodZone_RECOGNIZED_N_CIRCUMSCRIBED_FLOOD_ZONE   -0.000030\n",
      "50                            floodZone_RECOGNIZED_FLOOD_ZONE   -0.000064\n",
      "38                                           province_Limburg   -0.000066\n",
      "19                                        parkingCountOutdoor   -0.000289\n"
     ]
    }
   ],
   "source": [
    "# Applique le préprocessing uniquement\n",
    "preprocessed_X = best_pipeline[:-1].transform(X_test.drop(columns='id'))\n",
    "\n",
    "# Récupère les noms des colonnes après le TargetEncoder\n",
    "try:\n",
    "    feature_names = best_pipeline.named_steps['encoder'].get_feature_names_out()\n",
    "except:\n",
    "    # Fallback si ce n’est pas supporté\n",
    "    feature_names = X_test.drop(columns='id').columns  # ou crée des noms bidons si ça plante encore\n",
    "\n",
    "# Maintenant on construit le DataFrame correctement\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': r.importances_mean\n",
    "})\n",
    "\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(f\"model: {importance_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9623b2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost : MAE = 38534.1303, accuracy = 84.7865\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('encoder', ce.TargetEncoder(cols=['subtype', 'terraceOrientation'])),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train.drop(columns='id'), y_train)\n",
    "preds = pipeline.predict(X_test.drop(columns='id'))\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "errors = abs(preds - y_test)\n",
    "mape = 100 * (errors / y_test)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "\n",
    "print(f\"{best_model_name} : MAE = {mae:.4f}, accuracy = {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7d26d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

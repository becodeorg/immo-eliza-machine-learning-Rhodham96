{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d27b8e6a",
   "metadata": {},
   "source": [
    "# Prediction for houses and appartments with different regressions models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d5261b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8556ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from preprocessing import trainTestClean\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# Basic sklearn models\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85dbbe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = trainTestClean()\n",
    "\n",
    "X_train = df_train.drop(columns=['price', 'id'])\n",
    "y_train = df_train['price']\n",
    "X_test = df_test.drop(columns=['price', 'id'])\n",
    "y_test = df_test['price']\n",
    "\n",
    "X_test = X_test[X_train.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ab63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = StandardScaler()\n",
    "X_train = x_scaler.fit_transform(X_train)\n",
    "X_test = x_scaler.transform(X_test)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = y_scaler.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f9b544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select multiple models\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Lasso': Lasso(alpha=0.1),\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=0),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=2000, random_state=42, learning_rate=0.1),\n",
    "    'XGBoostElsa': xgb.XGBRegressor(n_estimators=2000, random_state=42, learning_rate=0.05, subsample= 0.8),\n",
    "    'XGBoostAlex': xgb.XGBRegressor(n_estimators=2500, random_state=42, learning_rate=0.08, subsample= 0.8),\n",
    "    'XGBoostAlex2': xgb.XGBRegressor(n_estimators=2500, random_state=42, learning_rate=0.08),\n",
    "    'XGBoostGridCV': xgb.XGBRegressor(n_estimators=3000, model__max_depth=7,random_state=42, learning_rate=0.01, subsample= 0.8),\n",
    "    'XGBoostBrutForce': xgb.XGBRegressor(colsample_bylevel=0.9289879319689553, colsample_bytree=0.7245003417617129, learning_rate=0.05183941032332593, max_depth=9, n_estimators=2496, reg_alpha=1.9905053073241674, reg_lambda=0.05061583846218687, subsample=0.7482424154252496),\n",
    "    'SVR': SVR(kernel='rbf', C=1.0, epsilon=0.2),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42),\n",
    "    'LightGBM': lgb.LGBMRegressor(random_state=42),\n",
    "    'CatBoost': CatBoostRegressor(random_state=42, silent=True),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'MLP': MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50d785ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression - Train : R2 = 0.6867, MAE = 71720.5729, MSE = 10822262051.7261, RMSE = 104030.1017\n",
      "LinearRegression - Test : R2 = 0.6889, MAE = 72497.5984, MSE = 10806612087.9954, RMSE = 103954.8560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+14, tolerance: 1.402e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso - Train : R2 = 0.6867, MAE = 71703.3783, MSE = 10822570642.6641, RMSE = 104031.5848\n",
      "Lasso - Test : R2 = 0.6890, MAE = 72460.1801, MSE = 10802712202.6497, RMSE = 103936.0967\n",
      "DecisionTree - Train : R2 = 1.0000, MAE = 0.0000, MSE = 0.0000, RMSE = 0.0000\n",
      "DecisionTree - Test : R2 = 0.9919, MAE = 4879.7646, MSE = 281147297.0871, RMSE = 16767.4475\n",
      "RandomForest - Train : R2 = 0.9997, MAE = 766.8673, MSE = 8666948.0418, RMSE = 2943.9681\n",
      "RandomForest - Test : R2 = 0.9983, MAE = 1876.8360, MSE = 60179974.8425, RMSE = 7757.5753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.540e+14, tolerance: 1.402e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet - Train : R2 = 0.5608, MAE = 83818.2875, MSE = 15171019840.6093, RMSE = 123170.6939\n",
      "ElasticNet - Test : R2 = 0.5584, MAE = 84558.8567, MSE = 15339566815.5196, RMSE = 123853.0049\n",
      "XGBoost - Train : R2 = 0.9999, MAE = 1097.3945, MSE = 2345429.7508, RMSE = 1531.4796\n",
      "XGBoost - Test : R2 = 0.9967, MAE = 3447.7501, MSE = 114130985.4916, RMSE = 10683.2104\n",
      "XGBoostElsa - Train : R2 = 0.9999, MAE = 1621.8871, MSE = 4760763.7889, RMSE = 2181.9175\n",
      "XGBoostElsa - Test : R2 = 0.9970, MAE = 3512.3140, MSE = 103262827.2953, RMSE = 10161.8319\n",
      "XGBoostAlex - Train : R2 = 0.9999, MAE = 986.9748, MSE = 1788913.3623, RMSE = 1337.5027\n",
      "XGBoostAlex - Test : R2 = 0.9965, MAE = 3557.0809, MSE = 122877792.9664, RMSE = 11085.0256\n",
      "XGBoostAlex2 - Train : R2 = 0.9999, MAE = 1042.5075, MSE = 2170148.1252, RMSE = 1473.1423\n",
      "XGBoostAlex2 - Test : R2 = 0.9970, MAE = 3343.4120, MSE = 104378981.3017, RMSE = 10216.6032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [12:26:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"model__max_depth\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoostGridCV - Train : R2 = 0.9995, MAE = 2734.2174, MSE = 15987454.7181, RMSE = 3998.4315\n",
      "XGBoostGridCV - Test : R2 = 0.9970, MAE = 3846.1223, MSE = 105533429.2667, RMSE = 10272.9465\n",
      "XGBoostBrutForce - Train : R2 = 1.0000, MAE = 312.5983, MSE = 201012.6662, RMSE = 448.3444\n",
      "XGBoostBrutForce - Test : R2 = 0.9925, MAE = 9435.2359, MSE = 260505747.6874, RMSE = 16140.1904\n",
      "SVR - Train : R2 = -0.0694, MAE = 137352.6645, MSE = 36941441552.4349, RMSE = 192201.5649\n",
      "SVR - Test : R2 = -0.0649, MAE = 137813.2190, MSE = 36991505135.6860, RMSE = 192331.7580\n",
      "GradientBoosting - Train : R2 = 0.9925, MAE = 10385.3162, MSE = 259162138.9572, RMSE = 16098.5136\n",
      "GradientBoosting - Test : R2 = 0.9916, MAE = 10881.9580, MSE = 290808701.8479, RMSE = 17053.1141\n",
      "AdaBoost - Train : R2 = 0.7131, MAE = 86154.7274, MSE = 9909749903.2223, RMSE = 99547.7268\n",
      "AdaBoost - Test : R2 = 0.7084, MAE = 87251.9402, MSE = 10127823804.2742, RMSE = 100637.0896\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2357\n",
      "[LightGBM] [Info] Number of data points in the train set: 40584, number of used features: 91\n",
      "[LightGBM] [Info] Start training from score 350867.736867\n",
      "LightGBM - Train : R2 = 0.9979, MAE = 5079.1279, MSE = 73692643.7059, RMSE = 8584.4420\n",
      "LightGBM - Test : R2 = 0.9975, MAE = 5332.1647, MSE = 86472455.7810, RMSE = 9299.0567\n",
      "CatBoost - Train : R2 = 0.9994, MAE = 3062.1548, MSE = 21519161.6890, RMSE = 4638.8750\n",
      "CatBoost - Test : R2 = 0.9982, MAE = 3506.0875, MSE = 63638543.2892, RMSE = 7977.3770\n",
      "Ridge - Train : R2 = 0.6853, MAE = 71728.5952, MSE = 10871006479.5162, RMSE = 104264.1188\n",
      "Ridge - Test : R2 = 0.6891, MAE = 72244.4169, MSE = 10801523138.8746, RMSE = 103930.3764\n",
      "MLP - Train : R2 = 0.9788, MAE = 19110.6567, MSE = 731360736.3710, RMSE = 27043.6820\n",
      "MLP - Test : R2 = 0.9792, MAE = 19269.0628, MSE = 721613228.6606, RMSE = 26862.8597\n",
      "Models results :\n",
      "LinearRegression : MAE = 72497.5984\n",
      "Lasso : MAE = 72460.1801\n",
      "DecisionTree : MAE = 4879.7646\n",
      "RandomForest : MAE = 1876.8360\n",
      "ElasticNet : MAE = 84558.8567\n",
      "XGBoost : MAE = 3447.7501\n",
      "XGBoostElsa : MAE = 3512.3140\n",
      "XGBoostAlex : MAE = 3557.0809\n",
      "XGBoostAlex2 : MAE = 3343.4120\n",
      "XGBoostGridCV : MAE = 3846.1223\n",
      "XGBoostBrutForce : MAE = 9435.2359\n",
      "SVR : MAE = 137813.2190\n",
      "GradientBoosting : MAE = 10881.9580\n",
      "AdaBoost : MAE = 87251.9402\n",
      "LightGBM : MAE = 5332.1647\n",
      "CatBoost : MAE = 3506.0875\n",
      "Ridge : MAE = 72244.4169\n",
      "MLP : MAE = 19269.0628\n",
      "\n",
      " -> Best Model : RandomForest with MAE = 1876.8360 and MSE = 60179974.8425; r2 = 0.9983\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "best_mae = float('inf')\n",
    "best_model_name = ''\n",
    "best_pipeline = Pipeline([])\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    preds = pipeline.predict(X_test)\n",
    "\n",
    "    preds_train = pipeline.predict(X_train)\n",
    "    preds_test = pipeline.predict(X_test)\n",
    "\n",
    "    #preds_train = y_scaler.inverse_transform(preds_train.reshape(-1, 1))\n",
    "    #preds_test = y_scaler.inverse_transform(preds_test.reshape(-1, 1))\n",
    "    #y_train = y_scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "    #y_test = y_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    r2_train = r2_score(y_train, preds_train)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, preds_train))\n",
    "    mae_train = mean_absolute_error(y_train, preds_train)\n",
    "    mse_train = mean_squared_error(y_train, preds_train)\n",
    "\n",
    "    print(f\"{name} - Train : R2 = {r2_train:.4f}, MAE = {mae_train:.4f}, MSE = {mse_train:.4f}, RMSE = {rmse_train:.4f}\")\n",
    "\n",
    "    r2_test = r2_score(y_test, preds_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, preds_test))\n",
    "    mae_test = mean_absolute_error(y_test, preds_test)\n",
    "    mse_test = mean_squared_error(y_test, preds_test)\n",
    "\n",
    "    print(f\"{name} - Test : R2 = {r2_test:.4f}, MAE = {mae_test:.4f}, MSE = {mse_test:.4f}, RMSE = {rmse_test:.4f}\")\n",
    "\n",
    "    results[name] = mae_test\n",
    "\n",
    "    if mae_test < best_mae:\n",
    "        best_mae = mae_test\n",
    "        best_mse = mse_test\n",
    "        best_r2 = r2_test\n",
    "        best_model_name = name\n",
    "        best_pipeline = pipeline\n",
    "        best_model = model\n",
    "\n",
    "print(\"Models results :\")\n",
    "for model_name, mae in results.items():\n",
    "    print(f\"{model_name} : MAE = {mae:.4f}\")\n",
    "\n",
    "print(f\"\\n -> Best Model : {best_model_name} with MAE = {best_mae:.4f} and MSE = {best_mse:.4f}; r2 = {best_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a57356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528fc928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

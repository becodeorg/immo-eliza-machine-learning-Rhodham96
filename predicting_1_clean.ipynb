{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0734e2c3",
   "metadata": {},
   "source": [
    "# IMMO-ELIZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16b32010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from category_encoders) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from category_encoders) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from category_encoders) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=1.6.0 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from category_encoders) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from category_encoders) (1.15.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from category_encoders) (0.14.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from scikit-learn>=1.6.0->category_encoders) (3.5.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: pgeocode in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pgeocode) (2.32.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pgeocode) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pgeocode) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pandas->pgeocode) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pandas->pgeocode) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from pandas->pgeocode) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from requests->pgeocode) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from requests->pgeocode) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from requests->pgeocode) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from requests->pgeocode) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/coursera/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->pgeocode) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders\n",
    "!pip install pgeocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cce13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ridge_regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pgeocode\n",
    "import xgboost as xgb\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9ce23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epcToNumeric(row):\n",
    "    region = row['region']\n",
    "    epc_score = row['epcScore']\n",
    "    \n",
    "    epc_mapping = {\n",
    "        'Flanders': {\n",
    "            'A++': 0,\n",
    "            'A+': 0,\n",
    "            'A': 100,\n",
    "            'B': 200,\n",
    "            'C': 300,\n",
    "            'D': 400,\n",
    "            'E': 500,\n",
    "            'F': 600,\n",
    "            'G': 700\n",
    "        },\n",
    "        'Wallonia': {\n",
    "            'A++': 0,\n",
    "            'A+': 50,\n",
    "            'A': 90,\n",
    "            'B': 170,\n",
    "            'C': 250,\n",
    "            'D': 330,\n",
    "            'E': 420,\n",
    "            'F': 510,\n",
    "            'G': 600\n",
    "        },\n",
    "        'Bruxelles': {\n",
    "            'A++': 0,\n",
    "            'A+': 0,\n",
    "            'A': 45,\n",
    "            'B': 95,\n",
    "            'C': 145,\n",
    "            'D': 210,\n",
    "            'E': 275,\n",
    "            'F': 345,\n",
    "            'G': 450\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return epc_mapping.get(region, {}).get(epc_score, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0065aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricePerM2(df):\n",
    "    df['pricePerM2'] = df['price']/df['habitableSurface']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0868822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoordinates(df):\n",
    "    nomi = pgeocode.Nominatim('be')\n",
    "    \n",
    "    unique_postcodes = df[\"postCode\"].astype(str).unique()\n",
    "\n",
    "    geo_df = nomi.query_postal_code(list(unique_postcodes))\n",
    "\n",
    "    geo_df = geo_df[['postal_code', 'latitude', 'longitude']]\n",
    "    geo_df = geo_df.rename(columns={'postal_code': 'postCode'})\n",
    "\n",
    "    df['postCode'] = df['postCode'].astype(str)\n",
    "    geo_df['postCode'] = geo_df['postCode'].astype(str)\n",
    "\n",
    "    df = df.merge(geo_df, on='postCode', how='left')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59e3c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a cleaning function :\n",
    "\n",
    "def transform_data_types(df, col_types):\n",
    "        for col, dtype in col_types.items():\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        return df\n",
    "\n",
    "def cleaning(df):\n",
    "    df = df.drop(columns=[\"Unnamed: 0\", \"url\"])\n",
    "\n",
    "    df = df.drop(columns=['monthlyCost', 'hasBalcony', 'accessibleDisabledPeople', 'roomCount', 'diningRoomSurface', \n",
    "                          'streetFacadeWidth', 'gardenOrientation', 'kitchenSurface', 'floorCount', 'hasDiningRoom', \n",
    "                          'hasDressingRoom'])\n",
    "    \n",
    "    \n",
    "    binary_cols = [\n",
    "        'hasBasement', 'hasLift', 'hasHeatPump', 'hasPhotovoltaicPanels', \n",
    "        'hasAirConditioning', 'hasArmoredDoor', 'hasVisiophone', 'hasOffice', \n",
    "        'hasSwimmingPool', 'hasFireplace', 'parkingCountIndoor', 'parkingCountOutdoor',\n",
    "        'hasAttic'\n",
    "    ]\n",
    "    \n",
    "    for col in binary_cols:\n",
    "        df[col] = df[col].map({True: 1, False: 0, 'True': 1, 'False': 0}).fillna(0).astype(int)\n",
    "    \n",
    "    # Colonnes dépendantes d'autres colonnes\n",
    "    df['hasLivingRoom'] = df['hasLivingRoom'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "    df.loc[df['hasLivingRoom'].isna(), 'hasLivingRoom'] = df['livingRoomSurface'].notnull().astype(int)\n",
    "    \n",
    "    df['hasGarden'] = df['hasGarden'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "    df.loc[df['hasGarden'].isna(), 'hasGarden'] = df['gardenSurface'].notnull().astype(int)\n",
    "    \n",
    "    df['hasTerrace'] = df['hasTerrace'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "    df.loc[df['hasTerrace'].isna(), 'hasTerrace'] = df['terraceSurface'].notnull().astype(int)\n",
    "    \n",
    "    # When hasLivingRoom = 0 ; livingRoomSurface = 0\n",
    "    df.loc[df['hasLivingRoom'] == 0, 'livingRoomSurface'] = 0\n",
    "    \n",
    "    # When hasGarden = 0 ; gardenSurface = 0\n",
    "    df.loc[df['hasGarden'] == 0, 'gardenSurface'] = 0\n",
    "    \n",
    "    # When hasTerrace = 0 ; terraceSurface = 0 and terraceOrientation = 0\n",
    "    df.loc[df['hasTerrace'] == 0, 'terraceSurface'] = 0\n",
    "    df.loc[df['hasTerrace'] == 0, 'terraceOrientation'] = 0\n",
    "    \n",
    "    #drop number of facade bigger than 4 and transform \"facedeCount\" into \"facadeCount\"\n",
    "    df['facadeCount'] = df['facedeCount']\n",
    "    df = df.drop(columns='facedeCount')\n",
    "    df['facadeCount'] = df['facadeCount'].fillna(2)\n",
    "    '''df = df[df['facadeCount'] <= 4]'''\n",
    "    \n",
    "    # bedroomCount : lets assume that they have at least one so fill nan by 1\n",
    "    df['bedroomCount'] = df['bedroomCount'].fillna(1).astype(float)\n",
    "    \n",
    "    # bathroomCount same as bedrooms\n",
    "    df['bathroomCount'] = df['bathroomCount'].fillna(1).astype(float)\n",
    "    \n",
    "    # toiletCount same as bedrooms\n",
    "    df['toiletCount'] = df['toiletCount'].fillna(1).astype(float)\n",
    "    \n",
    "    # habitableSurface : replace by median \n",
    "    #df['habitableSurface'] = df['habitableSurface'].fillna(df['habitableSurface'].median())\n",
    "    mediane_by_subtype = df.groupby('subtype')['habitableSurface'].median()\n",
    "    df['habitableSurface'] = df.apply(\n",
    "        lambda row: mediane_by_subtype[row['subtype']] if pd.isna(row['habitableSurface']) else row['habitableSurface'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # buildingCondition : replace by 'NOT_MENTIONED\n",
    "    df['buildingCondition'] = df['buildingCondition'].fillna('NOT_MENTIONED')\n",
    "    \n",
    "    # buildingConstructionYear\n",
    "    df['buildingConstructionYear'] = df['buildingConstructionYear'].fillna(df['buildingConstructionYear'].median()).astype(int)\n",
    "    \n",
    "    \n",
    "    # floodZoneType lts assume that missing values are NON_FLOOD_ZONE\n",
    "    df['floodZoneType'] = df['floodZoneType'].fillna('NON_FLOOD_ZONE')\n",
    "    \n",
    "    # heatingType\n",
    "    df['heatingType'] = df['heatingType'].fillna(df['heatingType'].mode()[0])\n",
    "    \n",
    "    # hasThermicPanels lets assume that if its not precised, there are not\n",
    "    df['hasThermicPanels'] = df['hasThermicPanels'].fillna(0).astype(float)\n",
    "    \n",
    "    # kitchenType\n",
    "    df['kitchenType'] = df['kitchenType'].fillna(df['kitchenType'].mode()[0])\n",
    "    \n",
    "    # landSurface\n",
    "    df['landSurface'] = df['landSurface'].fillna(df['landSurface'].median())\n",
    "    \n",
    "    # livingRoomSurface\n",
    "    df['livingRoomSurface'] = df['livingRoomSurface'].fillna(df['livingRoomSurface'].median())\n",
    "    \n",
    "    # terraceSurface\n",
    "    median_terrace = df.loc[(df['hasTerrace'] == 1) & (df['terraceSurface'].notnull()), 'terraceSurface'].median()\n",
    "    df.loc[(df['hasTerrace'] == 1) & (df['terraceSurface'].isna()), 'terraceSurface'] = median_terrace\n",
    "    df.loc[(df['hasTerrace'] != 1) & (df['terraceSurface'].isna()), 'terraceSurface'] = 0\n",
    "    \n",
    "    # terraceOrientation\n",
    "    mode_terrace = df.loc[(df['hasTerrace'] == 1), 'terraceOrientation'].mode()[0]\n",
    "    df.loc[(df['hasTerrace'] == 1) & (df['terraceOrientation'].isna()), 'terraceOrientation'] = mode_terrace\n",
    "    df.loc[(df['hasTerrace'] != 1) & (df['terraceOrientation'].isna()), 'terraceOrientation'] = 'NO_TERRACE'\n",
    "\n",
    "    \n",
    "    col_types = {'id': 'int', 'type': 'str', 'subtype': 'str', 'bedroomCount': 'int', 'bathroomCount': 'int',\n",
    "                 'province': 'str', 'locality': 'str', 'postCode': 'int', 'habitableSurface': 'float', \n",
    "                 'hasBasement': 'int', 'buildingCondition': 'str',\n",
    "                 'buildingConstructionYear': 'int', 'hasLift': 'int', 'floodZoneType': 'str',\n",
    "                 'heatingType': 'str', 'hasHeatPump': 'int', 'hasPhotovoltaicPanels': 'int', 'hasThermicPanels': 'int',\n",
    "                 'kitchenType': 'str', 'landSurface': 'float', 'hasLivingRoom': 'int', 'livingRoomSurface': 'float',\n",
    "                 'hasGarden': 'int', 'gardenSurface': 'float', 'parkingCountIndoor': 'int', 'parkingCountOutdoor': 'int',\n",
    "                 'hasAirConditioning': 'int', 'hasArmoredDoor': 'int', 'hasVisiophone': 'int', 'hasOffice': 'int', \n",
    "                 'toiletCount': 'int', 'hasSwimmingPool': 'int', 'hasFireplace': 'int', 'hasTerrace': 'int', 'terraceSurface': 'float',\n",
    "                 'terraceOrientation': 'str', 'epcScore': 'str', 'facadeCount': 'int'}\n",
    "    \n",
    "    df = transform_data_types(df, col_types)\n",
    "###\n",
    "###\n",
    "###\n",
    "    # Type into isHouse -> if false : Apartment\n",
    "    df['isHouse'] = (df['type'] == 'HOUSE').astype(int)\n",
    "\n",
    "    # subtype -> in pipeline\n",
    "\n",
    "    # province ? drop or dummies ?\n",
    "    df = pd.get_dummies(df, columns=['province'], prefix='province', dtype=int)\n",
    "    \n",
    "    # locality ? drop because zipcode\n",
    "\n",
    "    # building condition \n",
    "    condition_rating = {\n",
    "        'to restore': 0,\n",
    "        'to renovate': 1,\n",
    "        'to be done up': 2,\n",
    "        'good': 3,\n",
    "        'just renovated': 4,\n",
    "        'as new': 5\n",
    "    }\n",
    "    df['buildingCondition'] = (df['buildingCondition'].astype(str).str.strip().str.lower()\n",
    "                                    .map(condition_rating).fillna(-1).astype(int))\n",
    "\n",
    "    # floodzone type \n",
    "    df['floodZoneType'] = (df['floodZoneType'] != 'NON_FLOOD_ZONE').astype(int)\n",
    "    \n",
    "    # heatingType\n",
    "    df = pd.get_dummies(df, columns=['heatingType'], prefix='heating', dtype=int)\n",
    "    \n",
    "    # kitchenType\n",
    "    df = pd.get_dummies(df, columns=['kitchenType'], prefix='kitchen', dtype=int)\n",
    "\n",
    "    # add region information\n",
    "    def get_region(zip_code):\n",
    "        if 1000 <= zip_code <= 1299:\n",
    "            return \"Bruxelles\"\n",
    "        elif 1300 <= zip_code <= 1499 or 4000 <= zip_code <= 7999:\n",
    "            return \"Wallonia\"\n",
    "        else:\n",
    "            return \"Flanders\"\n",
    "    \n",
    "    df['region'] = df['postCode'].apply(get_region)\n",
    "\n",
    "    # epcScore\n",
    "    df['epcScore'] = df.apply(epcToNumeric, axis=1)\n",
    "\n",
    "    df = pricePerM2(df)\n",
    "    df = getCoordinates(df)\n",
    "    \n",
    "    df = df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "    df = df.drop(columns=['type', 'locality', 'region'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81886666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdePriceM2ProvinceKNN(df):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    coords_scaled = scaler.fit_transform(df[['latitude', 'longitude']])\n",
    "\n",
    "    k = 20 \n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    knn.fit(coords_scaled)\n",
    "    distances, indices = knn.kneighbors(coords_scaled)\n",
    "\n",
    "    kde_scores = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        neighbor_idxs = indices[i]\n",
    "        neighbor_prices = df['pricePerM2'].iloc[neighbor_idxs].dropna()\n",
    "\n",
    "        if len(neighbor_prices) < 2:\n",
    "            kde_scores.append(np.nan)\n",
    "        else:\n",
    "            kde = gaussian_kde(neighbor_prices)\n",
    "            density = kde(df['pricePerM2'].iloc[i])\n",
    "            kde_scores.append(density[0])\n",
    "\n",
    "    df['kde_price_per_m2_knn'] = kde_scores\n",
    "\n",
    "    df = df.drop(columns=['pricePerM2', 'latitude', 'longitude'])\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168c0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/Kangaroo.csv\")\n",
    "df = df.drop_duplicates(subset=[\"id\"], keep=\"first\")\n",
    "#df = df[(df['price']<2000000) & (df['price']>100000)]\n",
    "df = df[(df['price']<1000000) ]\n",
    "\n",
    "# drop lines without price\n",
    "df = df.dropna(subset=\"price\")\n",
    "# epcScore\n",
    "epc_order = ['A++', 'A+', 'A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "df = df[df['epcScore'].isin(epc_order)]\n",
    "df['epcScore'] = df['epcScore'].fillna(df['epcScore'].mode()[0])\n",
    "\n",
    "transform_data_types(df, {'price':float})\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = cleaning(df_train)\n",
    "df_test = cleaning(df_test)\n",
    "\n",
    "df_train = kdePriceM2ProvinceKNN(df_train)\n",
    "df_test = kdePriceM2ProvinceKNN(df_test)\n",
    "\n",
    "X_train = df_train.drop(columns=['price'])\n",
    "y_train = df_train['price']\n",
    "X_test = df_test.drop(columns=['price'])\n",
    "y_test = df_test['price']\n",
    "\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3129c72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              int64\n",
       "subtype                        object\n",
       "bedroomCount                    int64\n",
       "bathroomCount                   int64\n",
       "postCode                       object\n",
       "                               ...   \n",
       "kitchen_USA_HYPER_EQUIPPED      int64\n",
       "kitchen_USA_INSTALLED           int64\n",
       "kitchen_USA_SEMI_EQUIPPED       int64\n",
       "kitchen_USA_UNINSTALLED         int64\n",
       "kde_price_per_m2_knn          float64\n",
       "Length: 62, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcac69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression : MAE = 89984.1603, MSE = 15928704937.3619, accuracy = 69.5957\n",
      "Lasso : MAE = 89984.0817, MSE = 15928701927.3055, accuracy = 69.5957\n",
      "DecisionTree : MAE = 80516.3371, MSE = 14668202836.7372, accuracy = 74.1166\n",
      "RandomForest : MAE = 56494.0618, MSE = 6894266571.3988, accuracy = 81.4932\n",
      "ElasticNet : MAE = 92776.0046, MSE = 16949444545.7836, accuracy = 68.0657\n",
      "XGBoost : MAE = 50247.8558, MSE = 5488290954.6839, accuracy = 83.8174\n",
      "XGBoostElsa : MAE = 49760.4806, MSE = 5389791103.1069, accuracy = 83.9645\n",
      "SVR : MAE = 139031.6666, MSE = 37603554723.6041, accuracy = 54.3001\n",
      "GradientBoosting : MAE = 66794.3751, MSE = 9042786980.0018, accuracy = 77.6679\n",
      "AdaBoost : MAE = 132921.4580, MSE = 23376165644.2714, accuracy = 43.2115\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 48626, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score 352607.888208\n",
      "LightGBM : MAE = 57801.8225, MSE = 6822883152.6538, accuracy = 80.5197\n",
      "CatBoost : MAE = 52089.9887, MSE = 5789653864.1144, accuracy = 82.9508\n",
      "Ridge : MAE = 89983.6182, MSE = 15928663351.2969, accuracy = 69.5960\n",
      "MLP : MAE = 82066.7242, MSE = 13981889529.9279, accuracy = 72.7800\n",
      "Models results :\n",
      "LinearRegression : MAE = 89984.1603ler\n",
      "Lasso : MAE = 89984.0817ler\n",
      "DecisionTree : MAE = 80516.3371ler\n",
      "RandomForest : MAE = 56494.0618ler\n",
      "ElasticNet : MAE = 92776.0046ler\n",
      "XGBoost : MAE = 50247.8558ler\n",
      "XGBoostElsa : MAE = 49760.4806ler\n",
      "SVR : MAE = 139031.6666ler\n",
      "GradientBoosting : MAE = 66794.3751ler\n",
      "AdaBoost : MAE = 132921.4580ler\n",
      "LightGBM : MAE = 57801.8225ler\n",
      "CatBoost : MAE = 52089.9887ler\n",
      "Ridge : MAE = 89983.6182ler\n",
      "MLP : MAE = 82066.7242ler\n",
      "\n",
      " -> Best Model : XGBoostElsa with MAE = 49760.4806 and MSE = 5389791103.1069; accuracy = 83.9645\n"
     ]
    }
   ],
   "source": [
    "# select multiple models\n",
    "\n",
    "models = {\n",
    "    #'LinearRegression': LinearRegression(),\n",
    "    #'Lasso': linear_model.Lasso(alpha=0.1),\n",
    "    #'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    #'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    #'ElasticNet': ElasticNet(random_state=0),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=2000, random_state=42, learning_rate=0.1),\n",
    "    'XGBoostElsa': xgb.XGBRegressor(n_estimators=2000, random_state=42, learning_rate=0.05, subsample= 0.8),\n",
    "    'XGBoostAlex': xgb.XGBRegressor(n_estimators=2500, random_state=42, learning_rate=0.08, subsample= 0.8),\n",
    "    'XGBoostAlex2': xgb.XGBRegressor(n_estimators=2500, random_state=42, learning_rate=0.08),\n",
    "    #'SVR': SVR(kernel='rbf', C=1.0, epsilon=0.2),\n",
    "    #'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    #'AdaBoost': AdaBoostRegressor(random_state=42),\n",
    "    #'LightGBM': lgb.LGBMRegressor(random_state=42),\n",
    "    #'CatBoost': CatBoostRegressor(random_state=42, silent=True),\n",
    "    #'Ridge': Ridge(alpha=1.0),\n",
    "    #'MLP': MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_mae = float('inf')\n",
    "best_model_name = ''\n",
    "best_pipeline = Pipeline([])\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('encoder', ce.TargetEncoder(cols=['subtype', 'terraceOrientation'])),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train.drop(columns='id'), y_train)\n",
    "\n",
    "    preds = pipeline.predict(X_test.drop(columns='id'))\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "\n",
    "    errors = abs(preds - y_test)\n",
    "    mape = 100 * (errors / y_test)\n",
    "    # Calculate and display accuracy\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    print(f\"{name} : MAE = {mae:.4f}, MSE = {mse:.4f}, accuracy = {accuracy:.4f}\")\n",
    "\n",
    "    results[name] = mae\n",
    "\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_mse = mse\n",
    "        best_accuracy = accuracy\n",
    "        best_model_name = name\n",
    "        best_pipeline = pipeline\n",
    "        best_model = model\n",
    "\n",
    "print(\"Models results :\")\n",
    "for model_name, mae in results.items():\n",
    "    print(f\"{model_name} : MAE = {mae:.4f}ler\")\n",
    "\n",
    "print(f\"\\n -> Best Model : {best_model_name} with MAE = {best_mae:.4f} and MSE = {best_mse:.4f}; accuracy = {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623b2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost : MAE = 38534.1303, accuracy = 84.7865\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('encoder', ce.TargetEncoder(cols=['subtype', 'terraceOrientation'])),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train.drop(columns='id'), y_train)\n",
    "preds = pipeline.predict(X_test.drop(columns='id'))\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "errors = abs(preds - y_test)\n",
    "mape = 100 * (errors / y_test)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "\n",
    "print(f\"{best_model_name} : MAE = {mae:.4f}, accuracy = {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54942a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best params: {'model__learning_rate': 0.01, 'model__max_depth': 9, 'model__n_estimators': 3000, 'model__subsample': 0.8}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected input dimension 61, expected 62",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m---> 19\u001b[0m preds \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mpredict(X_test\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     21\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, preds)\n\u001b[1;32m     22\u001b[0m errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(preds \u001b[38;5;241m-\u001b[39m y_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/sklearn/model_selection/_search.py:598\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    the best found parameters.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/sklearn/pipeline.py:787\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 787\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/category_encoders/utils.py:622\u001b[0m, in \u001b[0;36mSupervisedTransformerMixin.transform\u001b[0;34m(self, X, y, override_return_df)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;66;03m# first check the type\u001b[39;00m\n\u001b[1;32m    621\u001b[0m X, y \u001b[38;5;241m=\u001b[39m convert_inputs(X, y, deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 622\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_transform_inputs(X)\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlab_encoder_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m     y \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlab_encoder_\u001b[38;5;241m.\u001b[39mtransform(y), index\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/coursera/lib/python3.11/site-packages/category_encoders/utils.py:514\u001b[0m, in \u001b[0;36mBaseEncoder._check_transform_inputs\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m# then make sure that it is the right size\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dim:\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected input dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected input dimension 61, expected 62"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    ('encoder', ce.TargetEncoder(cols=['subtype', 'terraceOrientation'])),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', xgb.XGBRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': [1000, 2000, 3000],\n",
    "    'model__max_depth': [5, 7, 9],\n",
    "    'model__learning_rate': [0.005, 0.01, 0.1, 0.2],\n",
    "    'model__subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "\n",
    "preds = grid_search.predict(X_test.drop(columns='id'))\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "errors = abs(preds - y_test)\n",
    "mape = 100 * (errors / y_test)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "\n",
    "print(f\"{best_model_name} : MAE = {mae:.4f}, accuracy = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7d26d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12fc3e2e",
   "metadata": {},
   "source": [
    "# TRY WITHOUT CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c7a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_simpler import trainTestClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2e15aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = trainTestClean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4209b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['price'])\n",
    "y_train = df_train['price']\n",
    "X_test = df_test.drop(columns=['price'])\n",
    "y_test = df_test['price']\n",
    "\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a2cdb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 82649.2875, MSE = 41837062011.6745\n"
     ]
    }
   ],
   "source": [
    "# select multiple models\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.031,\n",
    "    max_depth=9,\n",
    "    subsample=0.831,\n",
    "    colsample_bytree=0.395,\n",
    "    colsample_bylevel=0.449,\n",
    "    reg_alpha=1.769,\n",
    "    reg_lambda=3.922,\n",
    "    random_state=42,\n",
    "    tree_method='hist'\n",
    "    )\n",
    "\n",
    "\n",
    "model.fit(X_train.drop(columns='id'), y_train)\n",
    "\n",
    "preds = model.predict(X_test.drop(columns='id'))\n",
    "    \n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "\n",
    "print(f\"MAE = {mae:.4f}, MSE = {mse:.4f}\")\n",
    "#print(f\"MAE = {0}, MSE = {0}, accuracy = 100% you are the best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ffcb8a",
   "metadata": {},
   "source": [
    "# do nothing, clean nothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62f10e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score XGBoost : 0.7685086452971165\n"
     ]
    }
   ],
   "source": [
    "# 1. Conversion des booléens en 0/1\n",
    "bool_cols = [\n",
    "    'hasAttic', 'hasBasement', 'hasLift', 'hasHeatPump', 'hasPhotovoltaicPanels',\n",
    "    'hasThermicPanels', 'hasLivingRoom', 'hasGarden', 'hasAirConditioning',\n",
    "    'hasArmoredDoor', 'hasVisiophone', 'hasOffice', 'hasSwimmingPool',\n",
    "    'hasFireplace', 'hasTerrace'\n",
    "]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df[col] = df[col].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# 2. Encodage label des colonnes catégorielles\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col], _ = pd.factorize(df[col])\n",
    "\n",
    "# 3. On garde que les lignes avec un prix connu\n",
    "df = df[df[\"price\"].notnull()]\n",
    "\n",
    "# 4. Features et target\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "# 5. Split + entraînement rapide\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Score\n",
    "print(\"Score XGBoost :\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d277288c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                         object\n",
       "subtype                      object\n",
       "bedroomCount                float64\n",
       "bathroomCount               float64\n",
       "province                     object\n",
       "locality                     object\n",
       "postCode                      int64\n",
       "habitableSurface            float64\n",
       "hasAttic                     object\n",
       "hasBasement                  object\n",
       "buildingCondition            object\n",
       "buildingConstructionYear    float64\n",
       "facedeCount                 float64\n",
       "hasLift                      object\n",
       "floodZoneType                object\n",
       "heatingType                  object\n",
       "hasHeatPump                  object\n",
       "hasPhotovoltaicPanels        object\n",
       "hasThermicPanels             object\n",
       "kitchenType                  object\n",
       "landSurface                 float64\n",
       "hasLivingRoom                object\n",
       "livingRoomSurface           float64\n",
       "hasGarden                    object\n",
       "gardenSurface               float64\n",
       "gardenOrientation            object\n",
       "parkingCountIndoor          float64\n",
       "parkingCountOutdoor         float64\n",
       "hasAirConditioning           object\n",
       "hasArmoredDoor               object\n",
       "hasVisiophone                object\n",
       "hasOffice                    object\n",
       "toiletCount                 float64\n",
       "hasSwimmingPool              object\n",
       "hasFireplace                 object\n",
       "hasTerrace                   object\n",
       "terraceSurface              float64\n",
       "terraceOrientation           object\n",
       "epcScore                     object\n",
       "price                       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
